{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yk5ReltmxFIp"
      },
      "outputs": [],
      "source": [
        "kwargs = {\n",
        "    \"seed\": 42,\n",
        "    \"data_dir\": \"data/\",\n",
        "    \"train_dir\": \"outputs/multi_task_model\",\n",
        "    \"model_file\": \"outputs/pytorch_model.bin\",\n",
        "    \"model_id\": \"1U6Ek3c75RjxypFAj7_B-yfQ9NyDNk-eS\",\n",
        "    \"num_past_utterances\": 10,\n",
        "    \"num_future_utterances\": 0,\n",
        "    \"speaker_in_context\": False,\n",
        "    \"epoch\": 6,\n",
        "    \"learning_rate\": 1e-5,\n",
        "    \"batch_size\": 8,\n",
        "    \"do_train\": True,\n",
        "    \"checkpoint\": \"markussagen/xlm-roberta-longformer-base-4096\",\n",
        "    \"train_dataset\": [\"MELD\"],\n",
        "    \"train_task\": [\"Emotion\"],\n",
        "    \"eval_dataset\": \"MELD\",\n",
        "    \"eval_task\": \"Emotion\",\n",
        "    'output_file': 'outputs/predictions.out',\n",
        "    \"result_file\": \"results/scores.out\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nZtsUrmaxFIq"
      },
      "source": [
        "###Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "C_6HRADSxFIr",
        "outputId": "846919c6-3739-48fc-8e06-944e48b8d9a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "if kwargs[\"do_train\"]:\n",
        "  drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uq5jejz-xFIr",
        "outputId": "da6cffae-da99-4ca1-9166-ef00ed10f8fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-29 08:19:14--  https://raw.githubusercontent.com/UW-ling573-2022/data/main/MELD/dev_sent_emo.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 120527 (118K) [text/plain]\n",
            "Saving to: ‘dev_sent_emo.csv.8’\n",
            "\n",
            "\rdev_sent_emo.csv.8    0%[                    ]       0  --.-KB/s               \rdev_sent_emo.csv.8  100%[===================>] 117.70K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-05-29 08:19:14 (8.53 MB/s) - ‘dev_sent_emo.csv.8’ saved [120527/120527]\n",
            "\n",
            "--2022-05-29 08:19:14--  https://raw.githubusercontent.com/UW-ling573-2022/data/main/MELD/test_sent_emo.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 291912 (285K) [text/plain]\n",
            "Saving to: ‘test_sent_emo.csv.8’\n",
            "\n",
            "test_sent_emo.csv.8 100%[===================>] 285.07K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-05-29 08:19:14 (15.3 MB/s) - ‘test_sent_emo.csv.8’ saved [291912/291912]\n",
            "\n",
            "--2022-05-29 08:19:14--  https://raw.githubusercontent.com/UW-ling573-2022/data/main/MELD/train_sent_emo.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1109297 (1.1M) [text/plain]\n",
            "Saving to: ‘train_sent_emo.csv.8’\n",
            "\n",
            "train_sent_emo.csv. 100%[===================>]   1.06M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-05-29 08:19:14 (30.3 MB/s) - ‘train_sent_emo.csv.8’ saved [1109297/1109297]\n",
            "\n",
            "--2022-05-29 08:19:14--  https://raw.githubusercontent.com/UW-ling573-2022/data/main/EMORYNLP/dev.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 96597 (94K) [text/plain]\n",
            "Saving to: ‘dev.csv.8’\n",
            "\n",
            "dev.csv.8           100%[===================>]  94.33K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2022-05-29 08:19:14 (10.9 MB/s) - ‘dev.csv.8’ saved [96597/96597]\n",
            "\n",
            "--2022-05-29 08:19:14--  https://raw.githubusercontent.com/UW-ling573-2022/data/main/EMORYNLP/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 737779 (720K) [text/plain]\n",
            "Saving to: ‘train.csv.8’\n",
            "\n",
            "train.csv.8         100%[===================>] 720.49K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-05-29 08:19:14 (24.1 MB/s) - ‘train.csv.8’ saved [737779/737779]\n",
            "\n",
            "--2022-05-29 08:19:14--  https://raw.githubusercontent.com/UW-ling573-2022/data/main/EMORYNLP/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 96675 (94K) [text/plain]\n",
            "Saving to: ‘test.csv.8’\n",
            "\n",
            "test.csv.8          100%[===================>]  94.41K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-05-29 08:19:14 (9.27 MB/s) - ‘test.csv.8’ saved [96675/96675]\n",
            "\n",
            "--2022-05-29 08:19:15--  https://raw.githubusercontent.com/UW-ling573-2022/data/main/MPDD/dev_mpdd.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 148803 (145K) [text/plain]\n",
            "Saving to: ‘dev_mpdd.csv.8’\n",
            "\n",
            "dev_mpdd.csv.8      100%[===================>] 145.32K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-05-29 08:19:15 (10.3 MB/s) - ‘dev_mpdd.csv.8’ saved [148803/148803]\n",
            "\n",
            "--2022-05-29 08:19:15--  https://raw.githubusercontent.com/UW-ling573-2022/data/main/MPDD/train_mpdd.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2098288 (2.0M) [text/plain]\n",
            "Saving to: ‘train_mpdd.csv.8’\n",
            "\n",
            "train_mpdd.csv.8    100%[===================>]   2.00M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-05-29 08:19:15 (50.6 MB/s) - ‘train_mpdd.csv.8’ saved [2098288/2098288]\n",
            "\n",
            "--2022-05-29 08:19:15--  https://raw.githubusercontent.com/UW-ling573-2022/data/main/MPDD/test_mpdd.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 122202 (119K) [text/plain]\n",
            "Saving to: ‘test_mpdd.csv.8’\n",
            "\n",
            "test_mpdd.csv.8     100%[===================>] 119.34K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-05-29 08:19:15 (7.43 MB/s) - ‘test_mpdd.csv.8’ saved [122202/122202]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p data/MELD\n",
        "!cd data/MELD && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/MELD/dev_sent_emo.csv\n",
        "!cd data/MELD && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/MELD/test_sent_emo.csv\n",
        "!cd data/MELD && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/MELD/train_sent_emo.csv\n",
        "!mkdir -p data/EMORYNLP\n",
        "!cd data/EMORYNLP && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/EMORYNLP/dev.csv\n",
        "!cd data/EMORYNLP && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/EMORYNLP/train.csv\n",
        "!cd data/EMORYNLP && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/EMORYNLP/test.csv\n",
        "!mkdir -p data/MPDD\n",
        "!cd data/MPDD && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/MPDD/dev_mpdd.csv\n",
        "!cd data/MPDD && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/MPDD/train_mpdd.csv\n",
        "!cd data/MPDD && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/MPDD/test_mpdd.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "E4yyGA_fxFIs"
      },
      "outputs": [],
      "source": [
        "!mkdir -p outputs\n",
        "import gdown\n",
        "if kwargs[\"model_id\"] and not kwargs[\"do_train\"]:\n",
        "  gdown.download(id=kwargs[\"model_id\"], output=kwargs[\"model_file\"], quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VK8oHMrwxFIs",
        "outputId": "9eb9faf8-2f2a-420a-e3b4-8b5f9a54a509",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.7.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: dill<0.3.5 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.5.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mLyxBjLLxFIs"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import ClassLabel, load_metric, Dataset\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments\n",
        "from transformers import PreTrainedModel, PretrainedConfig\n",
        "from transformers import Trainer\n",
        "from transformers import is_datasets_available\n",
        "from transformers.trainer_pt_utils import IterableDatasetShard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nlOI4tVyxFIs"
      },
      "source": [
        "###MTL/data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "c3fxUYFHxFIt"
      },
      "outputs": [],
      "source": [
        "class SingleTaskDataLoader:\n",
        "    def __init__(self, task, **kwargs):\n",
        "        self.task = task\n",
        "        self.data_loader = DataLoader(**kwargs)\n",
        "        self.batch_size = self.data_loader.batch_size\n",
        "        self.dataset = self.data_loader.dataset\n",
        "        \n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data_loader)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for batch in self.data_loader:\n",
        "            batch[\"task\"] = self.task\n",
        "            yield batch\n",
        "    \n",
        "class MultiTaskDataLoader:\n",
        "    def __init__(self, task_data_loaders):\n",
        "        self.task_data_loaders = task_data_loaders\n",
        "        self.dataset = [None] * sum([len(dl.dataset) for dl in task_data_loaders.values()])\n",
        "        \n",
        "    def __len__(self) -> int:\n",
        "        return sum([len(dl) for dl in self.task_data_loaders.values()])\n",
        "    \n",
        "    def __iter__(self):\n",
        "        task_choices = []\n",
        "        for task, dl in self.task_data_loaders.items():\n",
        "            task_choices.extend([task] * len(dl))\n",
        "        task_choices = np.array(task_choices)\n",
        "        np.random.shuffle(task_choices)\n",
        "        for task in task_choices:\n",
        "            yield next(iter(self.task_data_loaders[task]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VzDBiU0QxFIt"
      },
      "source": [
        "###MTL/model.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "l9iyqSZ7xFIt"
      },
      "outputs": [],
      "source": [
        "class MultiTaskModel(PreTrainedModel):\n",
        "    def __init__(self, encoder, task_models):\n",
        "        super(MultiTaskModel, self).__init__(PretrainedConfig())\n",
        "        self.encoder = encoder\n",
        "        self.task_models = nn.ModuleDict(task_models)\n",
        "        \n",
        "    @classmethod\n",
        "    def from_task_models(cls, task_models):\n",
        "        shared_encoder = None\n",
        "        for model in task_models.values():\n",
        "            if shared_encoder is None:\n",
        "                shared_encoder = getattr(model, cls.get_encoder_attr_name(model))\n",
        "            else:\n",
        "                setattr(model, cls.get_encoder_attr_name(model), shared_encoder)\n",
        "        return cls(shared_encoder, task_models)\n",
        "                  \n",
        "    @staticmethod\n",
        "    def get_encoder_attr_name(model):\n",
        "        model_name = model.__class__.__name__\n",
        "        if model_name.startswith('Bert'):\n",
        "            return 'bert'\n",
        "        elif model_name.startswith('Roberta') or model_name.startswith(\"XLMRoberta\"):\n",
        "            return 'roberta'\n",
        "        elif model_name.startswith('Albert'):\n",
        "            return 'albert'\n",
        "        else:\n",
        "            raise ValueError('Unsupported model: {}'.format(model_name))\n",
        "        \n",
        "    def forward(self, task, input_ids, attention_mask, **kwargs):\n",
        "        model = self.task_models[task]\n",
        "        return model(input_ids, attention_mask, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "4ru_VY31xFIu"
      },
      "source": [
        "###MLT/train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-i5NGA5ZxFIu"
      },
      "outputs": [],
      "source": [
        "class MultiTaskTrainer(Trainer):\n",
        "\n",
        "    def get_single_task_dataloader(self, task, dataset, description):\n",
        "        if description == \"training\" and self.train_dataset is None:\n",
        "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
        "        elif description == \"evaluation\" and dataset is None and self.eval_dataset is None:\n",
        "            raise ValueError(\"Trainer: evaluation requires an eval_dataset.\")\n",
        "\n",
        "        if is_datasets_available() and isinstance(dataset, Dataset):\n",
        "            dataset = self._remove_unused_columns(dataset, description=description)\n",
        "\n",
        "        if isinstance(dataset, torch.utils.data.IterableDataset):\n",
        "            if self.args.world_size > 1:\n",
        "                dataset = IterableDatasetShard(\n",
        "                    dataset,\n",
        "                    batch_size=self.args.train_batch_size,\n",
        "                    drop_last=self.args.dataloader_drop_last,\n",
        "                    num_processes=self.args.world_size,\n",
        "                    process_index=self.args.process_index,\n",
        "                )\n",
        "\n",
        "            return SingleTaskDataLoader(\n",
        "                task,\n",
        "                dataset=dataset,\n",
        "                batch_size=self.args.per_device_train_batch_size,\n",
        "                collate_fn=self.data_collator,\n",
        "                num_workers=self.args.dataloader_num_workers,\n",
        "                pin_memory=self.args.dataloader_pin_memory,\n",
        "            )\n",
        "\n",
        "        if description == \"training\":\n",
        "            self.train_dataset, dataset = dataset, self.train_dataset\n",
        "            sampler = self._get_train_sampler()\n",
        "            self.train_dataset, dataset = dataset, self.train_dataset\n",
        "            batch_size = self.args.train_batch_size\n",
        "        else:\n",
        "            sampler = self._get_eval_sampler(dataset)\n",
        "            batch_size = self.args.eval_batch_size\n",
        "\n",
        "        return SingleTaskDataLoader(\n",
        "            task,\n",
        "            dataset=dataset,\n",
        "            batch_size=batch_size,\n",
        "            sampler=sampler,\n",
        "            collate_fn=self.data_collator,\n",
        "            drop_last=self.args.dataloader_drop_last,\n",
        "            num_workers=self.args.dataloader_num_workers,\n",
        "            pin_memory=self.args.dataloader_pin_memory,\n",
        "        )\n",
        "\n",
        "    def get_train_dataloader(self):\n",
        "        return MultiTaskDataLoader({\n",
        "            task: self.get_single_task_dataloader(task, dataset, description=\"training\")\n",
        "            for task, dataset in self.train_dataset.items()\n",
        "        })\n",
        "\n",
        "    def get_eval_dataloader(self, eval_dataset=None):\n",
        "        eval_dataset = eval_dataset if eval_dataset is not None else self.eval_dataset\n",
        "        task_to_eval = eval_dataset[\"task\"]\n",
        "        return self.get_single_task_dataloader(task_to_eval, eval_dataset[task_to_eval], description=\"evaluation\")\n",
        "\n",
        "    def get_test_dataloader(self, test_dataset):\n",
        "        task_to_test = test_dataset[\"task\"]\n",
        "        return self.get_single_task_dataloader(task_to_test, test_dataset[task_to_test], description=\"test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "TFG8hfR6xFIu"
      },
      "source": [
        "###preprocess.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uVQJ9QbxxFIu"
      },
      "outputs": [],
      "source": [
        "def preprocess(tokenizer, dataset_labels, **kwargs):\n",
        "\n",
        "    meld_files = {\n",
        "        \"train\": kwargs[\"data_dir\"] + \"MELD/train_sent_emo.csv\", \n",
        "        \"validation\": kwargs[\"data_dir\"] + \"MELD/dev_sent_emo.csv\",\n",
        "        \"test\": kwargs[\"data_dir\"] + \"MELD/test_sent_emo.csv\"\n",
        "    }\n",
        "    \n",
        "    emorynlp_files = {\n",
        "        \"train\": kwargs[\"data_dir\"] + \"EMORYNLP/train.csv\",\n",
        "        \"validation\": kwargs[\"data_dir\"] + \"EMORYNLP/dev.csv\",\n",
        "        \"test\": kwargs[\"data_dir\"] + \"EMORYNLP/test.csv\"\n",
        "    }\n",
        "    \n",
        "    mpdd_files = {\n",
        "        \"train\": kwargs[\"data_dir\"] + \"MPDD/train_mpdd.csv\", \n",
        "        \"validation\": kwargs[\"data_dir\"] + \"MPDD/dev_mpdd.csv\",\n",
        "        \"test\": kwargs[\"data_dir\"] + \"MPDD/test_mpdd.csv\"\n",
        "    }\n",
        "    \n",
        "    datasets = {\"MELD\": load_dataset(\"csv\", data_files=meld_files),\n",
        "                \"EmoryNLP\": load_dataset(\"csv\", data_files=emorynlp_files),\n",
        "                \"MPDD\": load_dataset(\"csv\", data_files=mpdd_files)}\n",
        "    \n",
        "    def encode_label(example, labels):\n",
        "        for task, label in labels.items():\n",
        "            if task == \"Speaker\":\n",
        "                example[task] = label.str2int(example[task]) \\\n",
        "                    if example[task] in label.names else label.str2int(\"Others\")\n",
        "            else:\n",
        "                example[task] = label.str2int(example[task])\n",
        "        return example\n",
        "\n",
        "    for name, dataset in datasets.items():\n",
        "        datasets[name] = dataset.map(lambda e: encode_label(e, dataset_labels[name]))\n",
        "\n",
        "    def add_context(example, idx, dataset, labels):\n",
        "        example[\"Past\"] = \"\"\n",
        "        example[\"Future\"] = \"\"\n",
        "\n",
        "        if example[\"Utterance_ID\"] != 0:\n",
        "            i = 1\n",
        "            while idx - i >= 0:\n",
        "                past = dataset[idx - i]\n",
        "                past_utterance = past[\"Utterance\"]\n",
        "                if \"Speaker\" in labels and kwargs[\"speaker_in_context\"]:\n",
        "                    past_speaker = labels[\"Speaker\"].int2str(past[\"Speaker\"])\n",
        "                    example[\"Past\"] = past_speaker + \":\" + past_utterance + \" \" + example[\"Past\"]\n",
        "                else:\n",
        "                    example[\"Past\"] = past_utterance + \" \" + example[\"Past\"]\n",
        "                if past[\"Utterance_ID\"] == 0 or i >= kwargs[\"num_past_utterances\"]:\n",
        "                    break\n",
        "                i += 1\n",
        "\n",
        "        if idx + 1 < len(dataset) and dataset[idx + 1][\"Utterance_ID\"] != 0:\n",
        "            i = 1\n",
        "            while idx + i < len(dataset):\n",
        "                future = dataset[idx + i]\n",
        "                future_utterance = future[\"Utterance\"]\n",
        "                if \"Speaker\" in labels and kwargs[\"speaker_in_context\"]:\n",
        "                    future_speaker = labels[\"Speaker\"].int2str(future[\"Speaker\"])\n",
        "                    example[\"Future\"] += \" \" + future_speaker + \":\" + future_utterance\n",
        "                else:\n",
        "                    example[\"Future\"] += \" \" + future_utterance\n",
        "                i += 1\n",
        "                if idx + i < len(dataset) and dataset[idx + i][\"Utterance_ID\"] == 0 \\\n",
        "                    or i >= kwargs[\"num_future_utterances\"]:\n",
        "                    break\n",
        "\n",
        "        return example\n",
        "\n",
        "    for name, dataset in datasets.items():\n",
        "        for split, ds in dataset.items():\n",
        "            dataset[split] = ds.map(lambda e, i: add_context(e, i, ds, dataset_labels[name]), with_indices=True)\n",
        "\n",
        "    def tokenize(example, add_past, add_future):\n",
        "        if add_past:\n",
        "            return tokenizer(example[\"Past\"], example[\"Utterance\"])\n",
        "        elif add_future:\n",
        "            return tokenizer(example[\"Utterance\"], example[\"Future\"])\n",
        "        else:\n",
        "            return tokenizer(example[\"Utterance\"])\n",
        "        \n",
        "    for name, dataset in datasets.items():\n",
        "        cx_datasets = {}\n",
        "        cx_datasets[\"with_past\"] = dataset.map(\n",
        "            lambda e: tokenize(e, add_past=True, add_future=False), batched=True)\n",
        "        cx_datasets[\"with_future\"] = dataset.map(\n",
        "            lambda e: tokenize(e, add_past=False, add_future=True), batched=True)\n",
        "        cx_datasets[\"no_context\"] = dataset.map(\n",
        "            lambda e: tokenize(e, add_past=False, add_future=False), batched=True)\n",
        "\n",
        "        tasks = list(dataset_labels[name].keys())\n",
        "        for cx in cx_datasets:\n",
        "            cols_to_keep = [\"input_ids\", \"attention_mask\"] + tasks\n",
        "            cols_to_remove = [c for c in cx_datasets[cx][\"train\"].column_names if c not in cols_to_keep]\n",
        "            cx_datasets[cx] = cx_datasets[cx].remove_columns(cols_to_remove)\n",
        "            task_datasets = {}\n",
        "            for task in tasks:\n",
        "                label = dataset_labels[name][task]\n",
        "                ds = cx_datasets[cx]\n",
        "                ds = ds.cast_column(task, label)\n",
        "                ds = ds.remove_columns([t for t in tasks if t != task])\n",
        "                ds = ds.rename_column(task, \"labels\")\n",
        "                ds.set_format()\n",
        "                task_datasets[task] = (ds, label)\n",
        "            cx_datasets[cx] = task_datasets\n",
        "        datasets[name] = cx_datasets\n",
        "\n",
        "    return datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "QoPgO9yqxFIv"
      },
      "source": [
        "###pipeline.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YvHbsfK-xFIv"
      },
      "outputs": [],
      "source": [
        "def prepare_datasets(datasets, **kwargs):\n",
        "    for dataset_name, cx_datasets in datasets.items():\n",
        "        task_dataset = {}\n",
        "        for split in [\"train\", \"validation\", \"test\"]:\n",
        "            task_dataset[split] = {}\n",
        "            for cx in cx_datasets:\n",
        "                if cx == \"with_past\" and kwargs[\"num_past_utterances\"] == 0:\n",
        "                    continue\n",
        "                elif cx == \"with_future\" and kwargs[\"num_future_utterances\"] == 0:\n",
        "                    continue\n",
        "                elif cx == \"no_context\" and kwargs[\"num_past_utterances\"] + kwargs[\"num_future_utterances\"] > 0:\n",
        "                    continue\n",
        "                else:\n",
        "                    for task, (ds, _) in cx_datasets[cx].items():\n",
        "                        if split == \"train\" and task not in kwargs[\"train_task\"]:\n",
        "                            continue\n",
        "                        if task not in task_dataset[split]:\n",
        "                            task_dataset[split][task] = ds[split]\n",
        "                        else:\n",
        "                            ds_to_concat = [task_dataset[split][task], ds[split]]\n",
        "                            task_dataset[split][task] = concatenate_datasets(ds_to_concat)\n",
        "\n",
        "        train_dataset = task_dataset[\"train\"]\n",
        "        eval_dataset = task_dataset[\"validation\"]\n",
        "        test_dataset = task_dataset[\"test\"]\n",
        "        \n",
        "        datasets[dataset_name] = {\"train\": train_dataset, \"validation\": eval_dataset, \"test\": test_dataset}\n",
        "        \n",
        "    train_dataset = {dataset_name + \"_\" + task: datasets[dataset_name][\"train\"][task] \n",
        "                     for dataset_name in datasets if dataset_name in kwargs[\"train_dataset\"]\n",
        "                     for task in datasets[dataset_name][\"train\"] if task in kwargs[\"train_task\"]}\n",
        "\n",
        "    eval_dataset_task = kwargs[\"eval_dataset\"] + \"_\" + kwargs[\"eval_task\"]\n",
        "    eval_dataset = {eval_dataset_task: datasets[kwargs[\"eval_dataset\"]][\"validation\"][kwargs[\"eval_task\"]]}\n",
        "    eval_dataset[\"task\"] = eval_dataset_task\n",
        "    test_dataset = {eval_dataset_task: datasets[kwargs[\"eval_dataset\"]][\"test\"][kwargs[\"eval_task\"]]}\n",
        "    test_dataset[\"task\"] = eval_dataset_task\n",
        "\n",
        "    return train_dataset, eval_dataset, test_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mx4s_QJ6xFIv",
        "outputId": "5d844b7c-322b-42dd-c7f3-e317cb2c3640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b3018eccf56a4cddb8e88c747559bbb4",
            "92f5b15d0bc64c95864693e6ef69d486",
            "1d08226a3bf245cd9608579aee955a01",
            "96457188fa4344448302f64a188bd9e7",
            "be4fb5f15e1c4dfcb458d70a0e19cb0e",
            "65ebef0d7981496db8959f3250f6e349",
            "7b3564df5db5417d8dc73962ef24e9b4",
            "68d0580cbf0d473bad648f5a37123b40",
            "9db78e4b8f7a4d8091494b7a698f431d",
            "d16e14c9ed5b4c2eb6e2fd4f7f5c2f6f",
            "d901d3e8cbcd4cd8820a498891aebeb6",
            "aa70276888524235b31dababf41da284",
            "8f617ca5e2ca4236abfc32be6e8e9946",
            "06db927f1fb34ec89e8d118cb6cf38c0",
            "1ffaeec3cf4c4373a42499a2281ab798",
            "80db56edc520427184e4efdee0392e8d",
            "d9afd44f85044afab86823a901877f10",
            "63b337c354824ca5b2eabdca0f59ee11",
            "319cf2d40bb14eddbed8b7730af5e460",
            "e81385592b28405fab7610512b6866f5",
            "4b3e422125c74d5ebfba214cb24daf15",
            "5a080234eca1488b98e1a808a0232b24",
            "a08f4f4a0d8e4fb5a62cb20894194178",
            "c6adaf6fe59842539106818ab7b3ae85",
            "10d68c7c275d4a88bab4896c1e1b1484",
            "9345dbf93a76417aa8b1aee6b7df0bbe",
            "eb9c17fd95c443128cdadd3a34312289",
            "bd81be88db5c4caaa71ce38623ca386f",
            "416745dbe2fb49a5bcac07b0a11ff753",
            "d6831a362cbb46fc82b30dd72dd4a946",
            "cc1df8846f174fc0bf56d264c31e3799",
            "f26dcedf1b7244238b4f897c365b3249",
            "544b72a905a14b9cba11b29ccb8099f3"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-0460ef81eef09c38\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3018eccf56a4cddb8e88c747559bbb4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-200f268ae07e8030\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa70276888524235b31dababf41da284"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-2bc3f446dfa1ff03\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a08f4f4a0d8e4fb5a62cb20894194178"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-02c5f2c5b05f1aa4.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-2681517591946c2a.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-abcaaa7183473aaa.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-a6b81c6507fda93a.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b3ba612d6a80ae5e.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-ec72b8ccdaaa48ad.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-471f50211ea3e8a3.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-dbf09ac5db600a66.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-0bf4d9bd645939fb.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-3be8e0a17e96b6f7.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-943eea7f211c3fd5.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-681035458cd02123.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-a99ddd4f91168a42.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-ee12bedf96353e17.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-9f6e1eaa54d93032.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-3c48da76fdced8d7.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-c58acab7f4a11168.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-19ad91e9c627c183.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-53a8eba9d4794263.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-d34a58211376237d.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-1f0fa23a971d5335.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-d6f0ec21484fe481.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-f57936008ca60e9c.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-341e62667f8d0bc7.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-021e52cfdcfc7b1f.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-de1969e865af942a.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-cef1cfadfb017645.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-c797862653fb5ec5.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-823d8b1c891c821d.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-a6446807891bfb13.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-98ea705bb0f99ff8.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-fef04248b5cf524c.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-48d2bc4321a53ef4.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-71df9bd0e3e8d25b.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-9ebe6a552d6116f0.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b19c26953990ef6d.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-04e4128ba1d4d6c0.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-6dfa9668ca784fb7.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-a5cbdbcf8896db47.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-cd70148a710e0857.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-8610410978815e4d.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b37b71c88f3e5e2d.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-f0b6a799a2de095d.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-8d5fd1d608d5f1d6.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-9bbca6d5034d4fcb.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-8e5051a5300a69d0.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-ead5d8197646d722.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-0ee4ff8004f9e256.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-2b01aa54b409d338.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-82a6da49382e5fcb.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-ec3222c0cda08d40.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-4d5d715fbd5fcf50.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-48dc0db1652f993f.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0460ef81eef09c38/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b57dc483d564d3d2.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b1c2eb910ed2b22b.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-26fcf6cdc87fdf2d.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-12e94dc1cc2b8b0a.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-989db26294018baa.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-2375c8ce1d2638f5.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-85783f6bb66408e2.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-0665a2b247a28206.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-3da000e11397670a.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-e93c0bb653107dba.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-cdb790ff1200ccf6.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-563fd61104b1dc0e.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-14081ee05e24b3e9.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-37eb7f177e79deff.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b7ad61286286e44b.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-c147a4b8026953ad.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-ea40a3f5cef7a7f4.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-587b8d23179dbd76.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-ce6063eaca849eca.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-5735c8eaec946e72.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-00f8e3da43f542f0.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-ef10bf42f9a783c1.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-0b9637cfeb55a8c1.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-f9d76d43d84704b1.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-09d61fa284eb54e7.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-85ce4a9951e9c052.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-3d869fc2667b5e13.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-200f268ae07e8030/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-d76ee5436f757bf4.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-6f92e0df206ee627.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-195abbfc152efe24.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-32251a7e96a94d08.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-4684a001529f40cf.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-e38e14d9690d77f5.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-e619cd6061a3741a.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-79320c195d4c13ca.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-e321f957e9bdd510.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-2af2fbfbd0bcdfc8.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-201e644399c169db.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-3dd854f00a43068f.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-1994861bc7c85211.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-582497bfde402c0f.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-2665de7e7b15a0cb.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-f6b293c06d2537ac.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-85dc13da7cfbd575.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-c1573ce2db22ae10.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2bc3f446dfa1ff03/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-4a1e0bb463e69c22.arrow\n"
          ]
        }
      ],
      "source": [
        "dataset_labels = {\n",
        "    \"MELD\": \n",
        "    {\n",
        "        \"Speaker\": ClassLabel(\n",
        "            num_classes=7,\n",
        "            names=[\"Chandler\", \"Joey\", \"Monica\", \"Rachel\", \"Ross\", \"Phoebe\", \"Others\"]),\n",
        "        \"Emotion\": ClassLabel(\n",
        "            num_classes=7,\n",
        "            names=[\"anger\", \"disgust\", \"fear\", \"joy\", \"neutral\", \"sadness\", \"surprise\"]),\n",
        "        \"Sentiment\": ClassLabel(\n",
        "            num_classes=3,\n",
        "            names=[\"positive\", \"neutral\", \"negative\"])\n",
        "    },\n",
        "    \"EmoryNLP\": \n",
        "    {   \n",
        "        \"Speaker\": ClassLabel(\n",
        "            num_classes=7,\n",
        "            names=[\"Chandler\", \"Joey\", \"Monica\", \"Rachel\", \"Ross\", \"Phoebe\", \"Others\"]),\n",
        "        \"Emotion\": ClassLabel(\n",
        "            num_classes=7,\n",
        "            names=[\"Sad\", \"Mad\", \"Scared\", \"Powerful\", \"Peaceful\", \"Joyful\", \"Neutral\"])\n",
        "    },\n",
        "    \"MPDD\": \n",
        "    {\n",
        "        \"Emotion\": ClassLabel(\n",
        "            num_classes=7,\n",
        "            names=[\"angry\", \"disgust\", \"fear\", \"joy\", \"neutral\", \"sadness\", \"surprise\"])\n",
        "    },\n",
        "}\n",
        "    \n",
        "tokenizer = AutoTokenizer.from_pretrained(kwargs[\"checkpoint\"])\n",
        "datasets = preprocess(tokenizer, dataset_labels, **kwargs)\n",
        "train_dataset, eval_dataset, test_dataset = prepare_datasets(datasets, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WPovLHVpxFIw",
        "outputId": "c9fc8d08-d2ef-4f7e-c9a7-3489a2238fc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at markussagen/xlm-roberta-longformer-base-4096 were not used when initializing XLMRobertaForSequenceClassification: ['roberta.encoder.layer.0.attention.self.key_global.bias', 'roberta.encoder.layer.3.attention.self.key_global.weight', 'roberta.encoder.layer.0.attention.self.query_global.weight', 'roberta.encoder.layer.5.attention.self.query_global.bias', 'roberta.encoder.layer.10.attention.self.value_global.bias', 'roberta.encoder.layer.8.attention.self.query_global.bias', 'roberta.encoder.layer.5.attention.self.key_global.bias', 'roberta.encoder.layer.11.attention.self.key_global.bias', 'roberta.encoder.layer.3.attention.self.value_global.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.4.attention.self.key_global.weight', 'roberta.encoder.layer.10.attention.self.key_global.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.10.attention.self.value_global.weight', 'roberta.encoder.layer.11.attention.self.query_global.bias', 'lm_head.bias', 'roberta.encoder.layer.4.attention.self.key_global.bias', 'roberta.encoder.layer.8.attention.self.value_global.weight', 'roberta.encoder.layer.2.attention.self.query_global.bias', 'roberta.encoder.layer.1.attention.self.query_global.weight', 'roberta.encoder.layer.1.attention.self.key_global.bias', 'roberta.encoder.layer.7.attention.self.key_global.weight', 'roberta.encoder.layer.5.attention.self.key_global.weight', 'roberta.encoder.layer.2.attention.self.key_global.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.1.attention.self.value_global.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.9.attention.self.value_global.bias', 'roberta.encoder.layer.9.attention.self.query_global.bias', 'roberta.encoder.layer.9.attention.self.query_global.weight', 'roberta.encoder.layer.1.attention.self.value_global.weight', 'roberta.encoder.layer.5.attention.self.value_global.bias', 'roberta.encoder.layer.9.attention.self.key_global.weight', 'roberta.encoder.layer.4.attention.self.value_global.weight', 'roberta.encoder.layer.11.attention.self.query_global.weight', 'roberta.encoder.layer.7.attention.self.query_global.weight', 'roberta.encoder.layer.6.attention.self.key_global.bias', 'roberta.encoder.layer.3.attention.self.key_global.bias', 'roberta.encoder.layer.7.attention.self.key_global.bias', 'roberta.encoder.layer.4.attention.self.value_global.bias', 'roberta.encoder.layer.10.attention.self.query_global.bias', 'roberta.encoder.layer.6.attention.self.query_global.weight', 'roberta.encoder.layer.7.attention.self.value_global.bias', 'roberta.encoder.layer.10.attention.self.key_global.weight', 'roberta.encoder.layer.7.attention.self.value_global.weight', 'roberta.encoder.layer.1.attention.self.key_global.weight', 'roberta.encoder.layer.10.attention.self.query_global.weight', 'roberta.encoder.layer.4.attention.self.query_global.bias', 'roberta.encoder.layer.0.attention.self.value_global.bias', 'roberta.encoder.layer.6.attention.self.value_global.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.8.attention.self.query_global.weight', 'roberta.encoder.layer.3.attention.self.value_global.bias', 'roberta.encoder.layer.11.attention.self.key_global.weight', 'roberta.encoder.layer.6.attention.self.key_global.weight', 'roberta.encoder.layer.7.attention.self.query_global.bias', 'roberta.encoder.layer.5.attention.self.query_global.weight', 'roberta.encoder.layer.4.attention.self.query_global.weight', 'roberta.encoder.layer.8.attention.self.key_global.bias', 'roberta.encoder.layer.2.attention.self.value_global.bias', 'roberta.encoder.layer.9.attention.self.key_global.bias', 'roberta.encoder.layer.11.attention.self.value_global.weight', 'roberta.encoder.layer.2.attention.self.value_global.weight', 'lm_head.decoder.bias', 'roberta.encoder.layer.0.attention.self.query_global.bias', 'roberta.encoder.layer.0.attention.self.key_global.weight', 'roberta.encoder.layer.11.attention.self.value_global.bias', 'roberta.encoder.layer.6.attention.self.value_global.bias', 'roberta.encoder.layer.3.attention.self.query_global.bias', 'roberta.encoder.layer.6.attention.self.query_global.bias', 'roberta.encoder.layer.5.attention.self.value_global.weight', 'roberta.encoder.layer.2.attention.self.key_global.bias', 'roberta.encoder.layer.2.attention.self.query_global.weight', 'roberta.encoder.layer.8.attention.self.value_global.bias', 'roberta.encoder.layer.1.attention.self.query_global.bias', 'roberta.encoder.layer.3.attention.self.query_global.weight', 'roberta.encoder.layer.8.attention.self.key_global.weight', 'roberta.encoder.layer.0.attention.self.value_global.weight', 'roberta.encoder.layer.9.attention.self.value_global.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at markussagen/xlm-roberta-longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tasks = {task: dataset_labels[task.split(\"_\")[0]][task.split(\"_\")[1]] for task in train_dataset.keys()}\n",
        "task_models = {\n",
        "        task: AutoModelForSequenceClassification.from_pretrained(\n",
        "            kwargs[\"checkpoint\"], \n",
        "            num_labels=label.num_classes,\n",
        "            max_length=1024)\n",
        "        for task, label in tasks.items()\n",
        "}\n",
        "multi_task_model = MultiTaskModel.from_task_models(task_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "brqjcRfFxFIw",
        "outputId": "e36a900f-a884-4694-d213-a2c3ec83a4a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JpgsubuzxFIw"
      },
      "outputs": [],
      "source": [
        "if not kwargs[\"do_train\"]:\n",
        "    multi_task_model.load_state_dict(\n",
        "        torch.load(kwargs[\"model_file\"], map_location=torch.device(device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QLFPNeOYxFIw",
        "outputId": "8aa2130c-115b-4642-e38d-befda2afde54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiTaskModel(\n",
              "  (encoder): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (task_models): ModuleDict(\n",
              "    (MELD_Emotion): XLMRobertaForSequenceClassification(\n",
              "      (roberta): RobertaModel(\n",
              "        (embeddings): RobertaEmbeddings(\n",
              "          (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "          (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
              "          (token_type_embeddings): Embedding(1, 768)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder): RobertaEncoder(\n",
              "          (layer): ModuleList(\n",
              "            (0): RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (1): RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (2): RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (3): RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (4): RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (5): RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (6): RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (7): RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (8): RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (9): RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (10): RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (11): RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (classifier): RobertaClassificationHead(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "multi_task_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Zue7FyktxFIw"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    metric = load_metric(\"f1\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=kwargs[\"train_dir\"],\n",
        "    seed=kwargs[\"seed\"],\n",
        "    overwrite_output_dir=True,\n",
        "    label_names=[\"labels\"],\n",
        "    learning_rate=kwargs[\"learning_rate\"],\n",
        "    num_train_epochs=kwargs[\"epoch\"],\n",
        "    per_device_train_batch_size=kwargs[\"batch_size\"],\n",
        "    logging_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    remove_unused_columns=False,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_f1\"\n",
        ")\n",
        "\n",
        "trainer = MultiTaskTrainer(\n",
        "    multi_task_model,\n",
        "    training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "B-oOLuqLxFIx",
        "outputId": "7ee68f75-c016-4c70-babd-c8ff56ed57cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799,
          "referenced_widgets": [
            "4a74f26701624482a0e94aa6785e2732",
            "ff2d7108af3446b5a038e96c0dab3401",
            "cffd61bb4bc94632bffd3202626d0eaf",
            "1d23a269165e41cab45fc7a8e6a328dd",
            "6295507bb4e04878ac5d90af20098995",
            "1aa45dbddecd4bf899e286628901d362",
            "18eafaba972046fba050675728add145",
            "0db7219f4c8843f7a844762e370a1ecb",
            "73e2a9e619e6420f97f372244dfe3a0d",
            "6a46f30cc5bb448cba76b911152cedf9",
            "8af6da589d924a8cb8c6a8288ebffe54"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 9989\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 7494\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1495' max='7494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1495/7494 04:56 < 19:51, 5.04 it/s, Epoch 1.20/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.409200</td>\n",
              "      <td>1.304453</td>\n",
              "      <td>0.520504</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1109\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a74f26701624482a0e94aa6785e2732"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to outputs/multi_task_model/checkpoint-1249\n",
            "Configuration saved in outputs/multi_task_model/checkpoint-1249/config.json\n",
            "Model weights saved in outputs/multi_task_model/checkpoint-1249/pytorch_model.bin\n",
            "tokenizer config file saved in outputs/multi_task_model/checkpoint-1249/tokenizer_config.json\n",
            "Special tokens file saved in outputs/multi_task_model/checkpoint-1249/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7f979643b77c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"do_train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         )\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1564\u001b[0m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtr_loss_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m                 \u001b[0;31m# Optimizer step for deepspeed must be called on every step regardless of the value of gradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mfloating_point_ops\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2916\u001b[0m         \"\"\"\n\u001b[1;32m   2917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"floating_point_ops\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2920\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfloating_point_ops\u001b[0;34m(self, input_dict, exclude_embeddings)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mnum_parameters\u001b[0;34m(self, only_trainable, exclude_embeddings)\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexclude_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             embedding_param_names = [\n\u001b[0;32m--> 785\u001b[0;31m                 \u001b[0;34mf\"{name}.weight\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m             ]\n\u001b[1;32m    787\u001b[0m             non_embedding_parameters = [\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexclude_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             embedding_param_names = [\n\u001b[0;32m--> 785\u001b[0;31m                 \u001b[0;34mf\"{name}.weight\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m             ]\n\u001b[1;32m    787\u001b[0m             non_embedding_parameters = [\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if kwargs[\"do_train\"]:\n",
        "    trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MetQKxvxxFIx"
      },
      "outputs": [],
      "source": [
        "pred = trainer.predict(test_dataset)\n",
        "f1 = pred.metrics['test_f1']\n",
        "print(\"Weighted F1:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "B9PORK38xFIx"
      },
      "outputs": [],
      "source": [
        "pred_labels = dataset_labels[kwargs[\"eval_dataset\"]][kwargs[\"eval_task\"]].int2str(pred.predictions.argmax(axis=-1))\n",
        "true_labels = dataset_labels[kwargs[\"eval_dataset\"]][kwargs[\"eval_task\"]].int2str(pred.label_ids)\n",
        "inputs = tokenizer.batch_decode(test_dataset[kwargs[\"eval_task\"]][\"input_ids\"])\n",
        "f = open(kwargs[\"output_file\"], \"w\")\n",
        "f.write(\"Input\\tPredicted\\tTrue\\n\")\n",
        "f.write(\"\\n\".join([\"\\t\".join([input, pred_label, true_label]) \n",
        "                    for input, pred_label, true_label \n",
        "                    in zip(inputs, pred_labels, true_labels)]))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "O-o6Eo2rxFIx"
      },
      "outputs": [],
      "source": [
        "!mkdir -p results\n",
        "import json\n",
        "\n",
        "f = open(kwargs[\"result_file\"], \"a+\")\n",
        "f.write(json.dumps(kwargs))\n",
        "f.write(\"\\nWeighted F1: {}\\n\".format(f1))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "n_uKa1B6xFIx"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(kwargs[\"result_file\"])\n",
        "files.download(kwargs[\"output_file\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "i1WthgWKxFIx"
      },
      "outputs": [],
      "source": [
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tmpJmvq2xFIy"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/outputs/multi_task_model/pytorch_model.bin\" \"/content/gdrive/MyDrive/pytorch_model.bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4QWKeLM-xFIy"
      },
      "outputs": [],
      "source": [
        "def get_random_sample(ds_test, tokenizer, idx=None, max_tokens=512):\n",
        "    while True:\n",
        "        if idx is None:\n",
        "            idx_ = np.random.randint(0, len(ds_test))\n",
        "        else:\n",
        "            idx_ = idx\n",
        "        random_sample = ds_test[idx_]\n",
        "        input_ids, attention_mask, labelid = (\n",
        "            random_sample[\"input_ids\"],\n",
        "            random_sample[\"attention_mask\"],\n",
        "            random_sample[\"labels\"],\n",
        "        )\n",
        "        break\n",
        "\n",
        "    decoded = tokenizer.decode(input_ids)\n",
        "\n",
        "    input_ids = torch.tensor(input_ids).view(-1, len(input_ids))\n",
        "    attention_mask = torch.tensor(attention_mask).view(-1, len(attention_mask))\n",
        "    labelid = torch.tensor(labelid).view(-1, 1)\n",
        "\n",
        "    return idx_, input_ids, attention_mask, labelid, decoded\n",
        "\n",
        "def return_coeffs(\n",
        "    tokenizer,\n",
        "    input_ids,\n",
        "    attentions,\n",
        "    BATCH_IDX=0,\n",
        "    LAYER=-1,\n",
        "    QUERY_TOKEN_IDX=0,\n",
        "    annoying_char=\"Ġ\",\n",
        "):\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[BATCH_IDX].tolist())\n",
        "    QUERY_TOKEN = tokens[QUERY_TOKEN_IDX].split(annoying_char)[-1]\n",
        "\n",
        "    coeffs = (\n",
        "        attentions[LAYER][BATCH_IDX].cpu().detach().numpy().sum(axis=0)[QUERY_TOKEN_IDX]\n",
        "    )\n",
        "    coeffs /= coeffs.sum()\n",
        "\n",
        "    idx_token_coeffs = [\n",
        "        (idx, token.split(annoying_char)[-1], coeffs[idx])\n",
        "        for idx, token in enumerate(tokens)\n",
        "    ]\n",
        "\n",
        "    assert len(coeffs) == len(tokens) == len(idx_token_coeffs)\n",
        "\n",
        "    return QUERY_TOKEN, coeffs, tokens, idx_token_coeffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qAP4C87cxFIy"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "ds_test = test_dataset[kwargs[\"evaluation\"]]\n",
        "idx, input_ids, attention_mask, labelid, decoded = get_random_sample(\n",
        "  ds_test, tokenizer\n",
        ")\n",
        "\n",
        "_, _, _, labelid_speaker, _ = get_random_sample(\n",
        "  test_dataset[\"Speaker\"], tokenizer, idx=idx\n",
        ")\n",
        "\n",
        "pprint.pprint(f\"{decoded}\")\n",
        "print()\n",
        "\n",
        "outputs = multi_task_model(\n",
        "  **{\"input_ids\": input_ids.to(device), \"attention_mask\": attention_mask.to(device)},\n",
        "  labels=labelid.to(device),\n",
        "  output_attentions=True,\n",
        "  output_hidden_states=True,\n",
        "  task=\"Emotion\"\n",
        ")\n",
        "\n",
        "#outputs_speaker = multi_task_model(\n",
        "#  **{\"input_ids\": input_ids.to(device), \"attention_mask\": attention_mask.to(device)},\n",
        "#  labels=labelid.to(device),\n",
        "#  output_attentions=True,\n",
        "#  output_hidden_states=True,\n",
        "#  task=\"Speaker\"\n",
        "#)\n",
        "\n",
        "attentions = outputs.attentions\n",
        "pred = labels[\"MELD\"][\"Emotion\"].int2str(int(outputs.logits.argmax().cpu().numpy()))\n",
        "truth = labels[\"MELD\"][\"Emotion\"].int2str(int(labelid[0][0].numpy()))\n",
        "\n",
        "#pred_speaker = labels[\"MELD\"][\"Speaker\"].int2str(int(outputs_speaker.logits.argmax().cpu().numpy()))\n",
        "#truth_speaker = labels[\"MELD\"][\"Speaker\"].int2str(int(labelid_speaker[0][0].numpy()))\n",
        "\n",
        "pprint.pprint(f\"data_idx: {idx}\")\n",
        "pprint.pprint(f\"pred: {pred}\")\n",
        "pprint.pprint(f\"truth: {truth}\")\n",
        "#pprint.pprint(f\"pred: {pred_speaker}\")\n",
        "#pprint.pprint(f\"truth: {truth_speaker}\")\n",
        "pprint.pprint(f\"number of tokens in the input: {input_ids.shape[1]}\")\n",
        "print()\n",
        "\n",
        "QUERY_TOKEN, coeffs, tokens, idx_token_coeffs = return_coeffs(\n",
        "    tokenizer, input_ids, attentions, LAYER=-1, QUERY_TOKEN_IDX=0\n",
        ")\n",
        "\n",
        "top_10 = sorted(idx_token_coeffs, key=lambda x: -x[2])[:10]\n",
        "print(top_10)\n",
        "print()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DmpSNfMXW8AW",
        "Y7LZ98xqW3sk",
        "3vu9ks2HWodt"
      ],
      "name": "D2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b3018eccf56a4cddb8e88c747559bbb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92f5b15d0bc64c95864693e6ef69d486",
              "IPY_MODEL_1d08226a3bf245cd9608579aee955a01",
              "IPY_MODEL_96457188fa4344448302f64a188bd9e7"
            ],
            "layout": "IPY_MODEL_be4fb5f15e1c4dfcb458d70a0e19cb0e"
          }
        },
        "92f5b15d0bc64c95864693e6ef69d486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65ebef0d7981496db8959f3250f6e349",
            "placeholder": "​",
            "style": "IPY_MODEL_7b3564df5db5417d8dc73962ef24e9b4",
            "value": "100%"
          }
        },
        "1d08226a3bf245cd9608579aee955a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68d0580cbf0d473bad648f5a37123b40",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9db78e4b8f7a4d8091494b7a698f431d",
            "value": 3
          }
        },
        "96457188fa4344448302f64a188bd9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d16e14c9ed5b4c2eb6e2fd4f7f5c2f6f",
            "placeholder": "​",
            "style": "IPY_MODEL_d901d3e8cbcd4cd8820a498891aebeb6",
            "value": " 3/3 [00:00&lt;00:00, 27.27it/s]"
          }
        },
        "be4fb5f15e1c4dfcb458d70a0e19cb0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65ebef0d7981496db8959f3250f6e349": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b3564df5db5417d8dc73962ef24e9b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68d0580cbf0d473bad648f5a37123b40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9db78e4b8f7a4d8091494b7a698f431d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d16e14c9ed5b4c2eb6e2fd4f7f5c2f6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d901d3e8cbcd4cd8820a498891aebeb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa70276888524235b31dababf41da284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f617ca5e2ca4236abfc32be6e8e9946",
              "IPY_MODEL_06db927f1fb34ec89e8d118cb6cf38c0",
              "IPY_MODEL_1ffaeec3cf4c4373a42499a2281ab798"
            ],
            "layout": "IPY_MODEL_80db56edc520427184e4efdee0392e8d"
          }
        },
        "8f617ca5e2ca4236abfc32be6e8e9946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9afd44f85044afab86823a901877f10",
            "placeholder": "​",
            "style": "IPY_MODEL_63b337c354824ca5b2eabdca0f59ee11",
            "value": "100%"
          }
        },
        "06db927f1fb34ec89e8d118cb6cf38c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_319cf2d40bb14eddbed8b7730af5e460",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e81385592b28405fab7610512b6866f5",
            "value": 3
          }
        },
        "1ffaeec3cf4c4373a42499a2281ab798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b3e422125c74d5ebfba214cb24daf15",
            "placeholder": "​",
            "style": "IPY_MODEL_5a080234eca1488b98e1a808a0232b24",
            "value": " 3/3 [00:00&lt;00:00,  9.42it/s]"
          }
        },
        "80db56edc520427184e4efdee0392e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9afd44f85044afab86823a901877f10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63b337c354824ca5b2eabdca0f59ee11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "319cf2d40bb14eddbed8b7730af5e460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e81385592b28405fab7610512b6866f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b3e422125c74d5ebfba214cb24daf15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a080234eca1488b98e1a808a0232b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a08f4f4a0d8e4fb5a62cb20894194178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6adaf6fe59842539106818ab7b3ae85",
              "IPY_MODEL_10d68c7c275d4a88bab4896c1e1b1484",
              "IPY_MODEL_9345dbf93a76417aa8b1aee6b7df0bbe"
            ],
            "layout": "IPY_MODEL_eb9c17fd95c443128cdadd3a34312289"
          }
        },
        "c6adaf6fe59842539106818ab7b3ae85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd81be88db5c4caaa71ce38623ca386f",
            "placeholder": "​",
            "style": "IPY_MODEL_416745dbe2fb49a5bcac07b0a11ff753",
            "value": "100%"
          }
        },
        "10d68c7c275d4a88bab4896c1e1b1484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6831a362cbb46fc82b30dd72dd4a946",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc1df8846f174fc0bf56d264c31e3799",
            "value": 3
          }
        },
        "9345dbf93a76417aa8b1aee6b7df0bbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f26dcedf1b7244238b4f897c365b3249",
            "placeholder": "​",
            "style": "IPY_MODEL_544b72a905a14b9cba11b29ccb8099f3",
            "value": " 3/3 [00:00&lt;00:00,  9.09it/s]"
          }
        },
        "eb9c17fd95c443128cdadd3a34312289": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd81be88db5c4caaa71ce38623ca386f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "416745dbe2fb49a5bcac07b0a11ff753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6831a362cbb46fc82b30dd72dd4a946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc1df8846f174fc0bf56d264c31e3799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f26dcedf1b7244238b4f897c365b3249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "544b72a905a14b9cba11b29ccb8099f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a74f26701624482a0e94aa6785e2732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff2d7108af3446b5a038e96c0dab3401",
              "IPY_MODEL_cffd61bb4bc94632bffd3202626d0eaf",
              "IPY_MODEL_1d23a269165e41cab45fc7a8e6a328dd"
            ],
            "layout": "IPY_MODEL_6295507bb4e04878ac5d90af20098995"
          }
        },
        "ff2d7108af3446b5a038e96c0dab3401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aa45dbddecd4bf899e286628901d362",
            "placeholder": "​",
            "style": "IPY_MODEL_18eafaba972046fba050675728add145",
            "value": "Downloading builder script: "
          }
        },
        "cffd61bb4bc94632bffd3202626d0eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0db7219f4c8843f7a844762e370a1ecb",
            "max": 2318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73e2a9e619e6420f97f372244dfe3a0d",
            "value": 2318
          }
        },
        "1d23a269165e41cab45fc7a8e6a328dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a46f30cc5bb448cba76b911152cedf9",
            "placeholder": "​",
            "style": "IPY_MODEL_8af6da589d924a8cb8c6a8288ebffe54",
            "value": " 6.50k/? [00:00&lt;00:00, 206kB/s]"
          }
        },
        "6295507bb4e04878ac5d90af20098995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aa45dbddecd4bf899e286628901d362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18eafaba972046fba050675728add145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0db7219f4c8843f7a844762e370a1ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e2a9e619e6420f97f372244dfe3a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a46f30cc5bb448cba76b911152cedf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8af6da589d924a8cb8c6a8288ebffe54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}