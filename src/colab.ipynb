{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yk5ReltmxFIp"
      },
      "outputs": [],
      "source": [
        "kwargs = {\n",
        "    \"seed\": 42,\n",
        "    \"data_dir\": \"data/\",\n",
        "    \"train_dir\": \"outputs/multi_task_model\",\n",
        "    \"model_file\": \"outputs/pytorch_model.bin\",\n",
        "    \"model_id\": \"1kZ8RmDj8K3HihmUiW2gJu8iyZ82cpbex\",\n",
        "    \"num_past_utterances\": 10,\n",
        "    \"num_future_utterances\": 0,\n",
        "    \"speaker_in_context\": False,\n",
        "    \"epoch\": 6,\n",
        "    \"learning_rate\": 1e-5,\n",
        "    \"batch_size\": 8,\n",
        "    \"do_train\": False,\n",
        "    \"checkpoint\": \"markussagen/xlm-roberta-longformer-base-4096\",\n",
        "    \"train_dataset\": [\"MPDD\", \"MELD\", \"EmoryNLP\"],\n",
        "    \"train_task\": [\"Emotion\"],\n",
        "    \"eval_dataset\": \"MPDD\",\n",
        "    \"eval_task\": \"Emotion\",\n",
        "    'output_file': 'outputs/predictions.out',\n",
        "    \"result_file\": \"results/scores.out\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nZtsUrmaxFIq"
      },
      "source": [
        "###Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "C_6HRADSxFIr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "if kwargs[\"do_train\"]:\n",
        "  drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uq5jejz-xFIr"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data/MELD\n",
        "!cd data/MELD && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/MELD/dev_sent_emo.csv\n",
        "!cd data/MELD && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/MELD/test_sent_emo.csv\n",
        "!cd data/MELD && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/MELD/train_sent_emo.csv\n",
        "!mkdir -p data/EMORYNLP\n",
        "!cd data/EMORYNLP && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/EMORYNLP/dev.csv\n",
        "!cd data/EMORYNLP && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/EMORYNLP/train.csv\n",
        "!cd data/EMORYNLP && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/EMORYNLP/test.csv\n",
        "!mkdir -p data/MPDD\n",
        "!cd data/MPDD && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/MPDD/dev_mpdd.csv\n",
        "!cd data/MPDD && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/MPDD/train_mpdd.csv\n",
        "!cd data/MPDD && wget https://raw.githubusercontent.com/UW-ling573-2022/data/main/MPDD/test_mpdd.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "E4yyGA_fxFIs"
      },
      "outputs": [],
      "source": [
        "!mkdir -p outputs\n",
        "import gdown\n",
        "if kwargs[\"model_id\"] and not kwargs[\"do_train\"]:\n",
        "  gdown.download(id=kwargs[\"model_id\"], output=kwargs[\"model_file\"], quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VK8oHMrwxFIs"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mLyxBjLLxFIs"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import ClassLabel, load_metric, Dataset\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments\n",
        "from transformers import PreTrainedModel, PretrainedConfig\n",
        "from transformers import Trainer\n",
        "from transformers import is_datasets_available\n",
        "from transformers.trainer_pt_utils import IterableDatasetShard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nlOI4tVyxFIs"
      },
      "source": [
        "###MTL/data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "c3fxUYFHxFIt"
      },
      "outputs": [],
      "source": [
        "class SingleTaskDataLoader:\n",
        "    def __init__(self, task, **kwargs):\n",
        "        self.task = task\n",
        "        self.data_loader = DataLoader(**kwargs)\n",
        "        self.batch_size = self.data_loader.batch_size\n",
        "        self.dataset = self.data_loader.dataset\n",
        "        \n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data_loader)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for batch in self.data_loader:\n",
        "            batch[\"task\"] = self.task\n",
        "            yield batch\n",
        "    \n",
        "class MultiTaskDataLoader:\n",
        "    def __init__(self, task_data_loaders):\n",
        "        self.task_data_loaders = task_data_loaders\n",
        "        self.dataset = [None] * sum([len(dl.dataset) for dl in task_data_loaders.values()])\n",
        "        \n",
        "    def __len__(self) -> int:\n",
        "        return sum([len(dl) for dl in self.task_data_loaders.values()])\n",
        "    \n",
        "    def __iter__(self):\n",
        "        task_choices = []\n",
        "        for task, dl in self.task_data_loaders.items():\n",
        "            task_choices.extend([task] * len(dl))\n",
        "        task_choices = np.array(task_choices)\n",
        "        np.random.shuffle(task_choices)\n",
        "        for task in task_choices:\n",
        "            yield next(iter(self.task_data_loaders[task]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VzDBiU0QxFIt"
      },
      "source": [
        "###MTL/model.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "l9iyqSZ7xFIt"
      },
      "outputs": [],
      "source": [
        "class MultiTaskModel(PreTrainedModel):\n",
        "    def __init__(self, encoder, task_models):\n",
        "        super(MultiTaskModel, self).__init__(PretrainedConfig())\n",
        "        self.encoder = encoder\n",
        "        self.task_models = nn.ModuleDict(task_models)\n",
        "        \n",
        "    @classmethod\n",
        "    def from_task_models(cls, task_models):\n",
        "        shared_encoder = None\n",
        "        for model in task_models.values():\n",
        "            if shared_encoder is None:\n",
        "                shared_encoder = getattr(model, cls.get_encoder_attr_name(model))\n",
        "            else:\n",
        "                setattr(model, cls.get_encoder_attr_name(model), shared_encoder)\n",
        "        return cls(shared_encoder, task_models)\n",
        "                  \n",
        "    @staticmethod\n",
        "    def get_encoder_attr_name(model):\n",
        "        model_name = model.__class__.__name__\n",
        "        if model_name.startswith('Bert'):\n",
        "            return 'bert'\n",
        "        elif model_name.startswith('Roberta') or model_name.startswith(\"XLMRoberta\"):\n",
        "            return 'roberta'\n",
        "        elif model_name.startswith('Albert'):\n",
        "            return 'albert'\n",
        "        else:\n",
        "            raise ValueError('Unsupported model: {}'.format(model_name))\n",
        "        \n",
        "    def forward(self, task, input_ids, attention_mask, **kwargs):\n",
        "        model = self.task_models[task]\n",
        "        return model(input_ids, attention_mask, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "4ru_VY31xFIu"
      },
      "source": [
        "###MLT/train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-i5NGA5ZxFIu"
      },
      "outputs": [],
      "source": [
        "class MultiTaskTrainer(Trainer):\n",
        "\n",
        "    def get_single_task_dataloader(self, task, dataset, description):\n",
        "        if description == \"training\" and self.train_dataset is None:\n",
        "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
        "        elif description == \"evaluation\" and dataset is None and self.eval_dataset is None:\n",
        "            raise ValueError(\"Trainer: evaluation requires an eval_dataset.\")\n",
        "\n",
        "        if is_datasets_available() and isinstance(dataset, Dataset):\n",
        "            dataset = self._remove_unused_columns(dataset, description=description)\n",
        "\n",
        "        if isinstance(dataset, torch.utils.data.IterableDataset):\n",
        "            if self.args.world_size > 1:\n",
        "                dataset = IterableDatasetShard(\n",
        "                    dataset,\n",
        "                    batch_size=self.args.train_batch_size,\n",
        "                    drop_last=self.args.dataloader_drop_last,\n",
        "                    num_processes=self.args.world_size,\n",
        "                    process_index=self.args.process_index,\n",
        "                )\n",
        "\n",
        "            return SingleTaskDataLoader(\n",
        "                task,\n",
        "                dataset=dataset,\n",
        "                batch_size=self.args.per_device_train_batch_size,\n",
        "                collate_fn=self.data_collator,\n",
        "                num_workers=self.args.dataloader_num_workers,\n",
        "                pin_memory=self.args.dataloader_pin_memory,\n",
        "            )\n",
        "\n",
        "        if description == \"training\":\n",
        "            self.train_dataset, dataset = dataset, self.train_dataset\n",
        "            sampler = self._get_train_sampler()\n",
        "            self.train_dataset, dataset = dataset, self.train_dataset\n",
        "            batch_size = self.args.train_batch_size\n",
        "        else:\n",
        "            sampler = self._get_eval_sampler(dataset)\n",
        "            batch_size = self.args.eval_batch_size\n",
        "\n",
        "        return SingleTaskDataLoader(\n",
        "            task,\n",
        "            dataset=dataset,\n",
        "            batch_size=batch_size,\n",
        "            sampler=sampler,\n",
        "            collate_fn=self.data_collator,\n",
        "            drop_last=self.args.dataloader_drop_last,\n",
        "            num_workers=self.args.dataloader_num_workers,\n",
        "            pin_memory=self.args.dataloader_pin_memory,\n",
        "        )\n",
        "\n",
        "    def get_train_dataloader(self):\n",
        "        return MultiTaskDataLoader({\n",
        "            task: self.get_single_task_dataloader(task, dataset, description=\"training\")\n",
        "            for task, dataset in self.train_dataset.items()\n",
        "        })\n",
        "\n",
        "    def get_eval_dataloader(self, eval_dataset=None):\n",
        "        eval_dataset = eval_dataset if eval_dataset is not None else self.eval_dataset\n",
        "        task_to_eval = eval_dataset[\"task\"]\n",
        "        return self.get_single_task_dataloader(task_to_eval, eval_dataset[task_to_eval], description=\"evaluation\")\n",
        "\n",
        "    def get_test_dataloader(self, test_dataset):\n",
        "        task_to_test = test_dataset[\"task\"]\n",
        "        return self.get_single_task_dataloader(task_to_test, test_dataset[task_to_test], description=\"test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "TFG8hfR6xFIu"
      },
      "source": [
        "###preprocess.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uVQJ9QbxxFIu"
      },
      "outputs": [],
      "source": [
        "def preprocess(tokenizer, dataset_labels, **kwargs):\n",
        "\n",
        "    meld_files = {\n",
        "        \"train\": kwargs[\"data_dir\"] + \"MELD/train_sent_emo.csv\", \n",
        "        \"validation\": kwargs[\"data_dir\"] + \"MELD/dev_sent_emo.csv\",\n",
        "        \"test\": kwargs[\"data_dir\"] + \"MELD/test_sent_emo.csv\"\n",
        "    }\n",
        "    \n",
        "    emorynlp_files = {\n",
        "        \"train\": kwargs[\"data_dir\"] + \"EMORYNLP/train.csv\",\n",
        "        \"validation\": kwargs[\"data_dir\"] + \"EMORYNLP/dev.csv\",\n",
        "        \"test\": kwargs[\"data_dir\"] + \"EMORYNLP/test.csv\"\n",
        "    }\n",
        "    \n",
        "    mpdd_files = {\n",
        "        \"train\": kwargs[\"data_dir\"] + \"MPDD/train_mpdd.csv\", \n",
        "        \"validation\": kwargs[\"data_dir\"] + \"MPDD/dev_mpdd.csv\",\n",
        "        \"test\": kwargs[\"data_dir\"] + \"MPDD/test_mpdd.csv\"\n",
        "    }\n",
        "    \n",
        "    datasets = {\"MELD\": load_dataset(\"csv\", data_files=meld_files),\n",
        "                \"EmoryNLP\": load_dataset(\"csv\", data_files=emorynlp_files),\n",
        "                \"MPDD\": load_dataset(\"csv\", data_files=mpdd_files)}\n",
        "    \n",
        "    def encode_label(example, labels):\n",
        "        for task, label in labels.items():\n",
        "            if task == \"Speaker\":\n",
        "                example[task] = label.str2int(example[task]) \\\n",
        "                    if example[task] in label.names else label.str2int(\"Others\")\n",
        "            else:\n",
        "                example[task] = label.str2int(example[task])\n",
        "        return example\n",
        "\n",
        "    for name, dataset in datasets.items():\n",
        "        datasets[name] = dataset.map(lambda e: encode_label(e, dataset_labels[name]))\n",
        "\n",
        "    def add_context(example, idx, dataset, labels):\n",
        "        example[\"Past\"] = \"\"\n",
        "        example[\"Future\"] = \"\"\n",
        "\n",
        "        if example[\"Utterance_ID\"] != 0:\n",
        "            i = 1\n",
        "            while idx - i >= 0:\n",
        "                past = dataset[idx - i]\n",
        "                past_utterance = past[\"Utterance\"]\n",
        "                if \"Speaker\" in labels and kwargs[\"speaker_in_context\"]:\n",
        "                    past_speaker = labels[\"Speaker\"].int2str(past[\"Speaker\"])\n",
        "                    example[\"Past\"] = past_speaker + \":\" + past_utterance + \" \" + example[\"Past\"]\n",
        "                else:\n",
        "                    example[\"Past\"] = past_utterance + \" \" + example[\"Past\"]\n",
        "                if past[\"Utterance_ID\"] == 0 or i >= kwargs[\"num_past_utterances\"]:\n",
        "                    break\n",
        "                i += 1\n",
        "\n",
        "        if idx + 1 < len(dataset) and dataset[idx + 1][\"Utterance_ID\"] != 0:\n",
        "            i = 1\n",
        "            while idx + i < len(dataset):\n",
        "                future = dataset[idx + i]\n",
        "                future_utterance = future[\"Utterance\"]\n",
        "                if \"Speaker\" in labels and kwargs[\"speaker_in_context\"]:\n",
        "                    future_speaker = labels[\"Speaker\"].int2str(future[\"Speaker\"])\n",
        "                    example[\"Future\"] += \" \" + future_speaker + \":\" + future_utterance\n",
        "                else:\n",
        "                    example[\"Future\"] += \" \" + future_utterance\n",
        "                i += 1\n",
        "                if idx + i < len(dataset) and dataset[idx + i][\"Utterance_ID\"] == 0 \\\n",
        "                    or i >= kwargs[\"num_future_utterances\"]:\n",
        "                    break\n",
        "\n",
        "        return example\n",
        "\n",
        "    for name, dataset in datasets.items():\n",
        "        for split, ds in dataset.items():\n",
        "            dataset[split] = ds.map(lambda e, i: add_context(e, i, ds, dataset_labels[name]), with_indices=True)\n",
        "\n",
        "    def tokenize(example, add_past, add_future):\n",
        "        if add_past:\n",
        "            return tokenizer(example[\"Past\"], example[\"Utterance\"])\n",
        "        elif add_future:\n",
        "            return tokenizer(example[\"Utterance\"], example[\"Future\"])\n",
        "        else:\n",
        "            return tokenizer(example[\"Utterance\"])\n",
        "        \n",
        "    for name, dataset in datasets.items():\n",
        "        cx_datasets = {}\n",
        "        cx_datasets[\"with_past\"] = dataset.map(\n",
        "            lambda e: tokenize(e, add_past=True, add_future=False), batched=True)\n",
        "        cx_datasets[\"with_future\"] = dataset.map(\n",
        "            lambda e: tokenize(e, add_past=False, add_future=True), batched=True)\n",
        "        cx_datasets[\"no_context\"] = dataset.map(\n",
        "            lambda e: tokenize(e, add_past=False, add_future=False), batched=True)\n",
        "\n",
        "        tasks = list(dataset_labels[name].keys())\n",
        "        for cx in cx_datasets:\n",
        "            cols_to_keep = [\"input_ids\", \"attention_mask\"] + tasks\n",
        "            cols_to_remove = [c for c in cx_datasets[cx][\"train\"].column_names if c not in cols_to_keep]\n",
        "            cx_datasets[cx] = cx_datasets[cx].remove_columns(cols_to_remove)\n",
        "            task_datasets = {}\n",
        "            for task in tasks:\n",
        "                label = dataset_labels[name][task]\n",
        "                ds = cx_datasets[cx]\n",
        "                ds = ds.cast_column(task, label)\n",
        "                ds = ds.remove_columns([t for t in tasks if t != task])\n",
        "                ds = ds.rename_column(task, \"labels\")\n",
        "                ds.set_format()\n",
        "                task_datasets[task] = (ds, label)\n",
        "            cx_datasets[cx] = task_datasets\n",
        "        datasets[name] = cx_datasets\n",
        "\n",
        "    return datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "QoPgO9yqxFIv"
      },
      "source": [
        "###pipeline.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YvHbsfK-xFIv"
      },
      "outputs": [],
      "source": [
        "def prepare_datasets(datasets, **kwargs):\n",
        "    for dataset_name, cx_datasets in datasets.items():\n",
        "        task_dataset = {}\n",
        "        for split in [\"train\", \"validation\", \"test\"]:\n",
        "            task_dataset[split] = {}\n",
        "            for cx in cx_datasets:\n",
        "                if cx == \"with_past\" and kwargs[\"num_past_utterances\"] == 0:\n",
        "                    continue\n",
        "                elif cx == \"with_future\" and kwargs[\"num_future_utterances\"] == 0:\n",
        "                    continue\n",
        "                elif cx == \"no_context\" and kwargs[\"num_past_utterances\"] + kwargs[\"num_future_utterances\"] > 0:\n",
        "                    continue\n",
        "                else:\n",
        "                    for task, (ds, _) in cx_datasets[cx].items():\n",
        "                        if split == \"train\" and task not in kwargs[\"train_task\"]:\n",
        "                            continue\n",
        "                        if task not in task_dataset[split]:\n",
        "                            task_dataset[split][task] = ds[split]\n",
        "                        else:\n",
        "                            ds_to_concat = [task_dataset[split][task], ds[split]]\n",
        "                            task_dataset[split][task] = concatenate_datasets(ds_to_concat)\n",
        "\n",
        "        train_dataset = task_dataset[\"train\"]\n",
        "        eval_dataset = task_dataset[\"validation\"]\n",
        "        test_dataset = task_dataset[\"test\"]\n",
        "        \n",
        "        datasets[dataset_name] = {\"train\": train_dataset, \"validation\": eval_dataset, \"test\": test_dataset}\n",
        "        \n",
        "    train_dataset = {dataset_name + \"_\" + task: datasets[dataset_name][\"train\"][task] \n",
        "                     for dataset_name in datasets if dataset_name in kwargs[\"train_dataset\"]\n",
        "                     for task in datasets[dataset_name][\"train\"] if task in kwargs[\"train_task\"]}\n",
        "\n",
        "    eval_dataset_task = kwargs[\"eval_dataset\"] + \"_\" + kwargs[\"eval_task\"]\n",
        "    eval_dataset = {eval_dataset_task: datasets[kwargs[\"eval_dataset\"]][\"validation\"][kwargs[\"eval_task\"]]}\n",
        "    eval_dataset[\"task\"] = eval_dataset_task\n",
        "    test_dataset = {eval_dataset_task: datasets[kwargs[\"eval_dataset\"]][\"test\"][kwargs[\"eval_task\"]]}\n",
        "    test_dataset[\"task\"] = eval_dataset_task\n",
        "\n",
        "    return train_dataset, eval_dataset, test_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mx4s_QJ6xFIv"
      },
      "outputs": [],
      "source": [
        "dataset_labels = {\n",
        "    \"MELD\": \n",
        "    {\n",
        "        \"Speaker\": ClassLabel(\n",
        "            num_classes=7,\n",
        "            names=[\"Chandler\", \"Joey\", \"Monica\", \"Rachel\", \"Ross\", \"Phoebe\", \"Others\"]),\n",
        "        \"Emotion\": ClassLabel(\n",
        "            num_classes=7,\n",
        "            names=[\"anger\", \"disgust\", \"fear\", \"joy\", \"neutral\", \"sadness\", \"surprise\"]),\n",
        "        \"Sentiment\": ClassLabel(\n",
        "            num_classes=3,\n",
        "            names=[\"positive\", \"neutral\", \"negative\"])\n",
        "    },\n",
        "    \"EmoryNLP\": \n",
        "    {   \n",
        "        \"Speaker\": ClassLabel(\n",
        "            num_classes=7,\n",
        "            names=[\"Chandler\", \"Joey\", \"Monica\", \"Rachel\", \"Ross\", \"Phoebe\", \"Others\"]),\n",
        "        \"Emotion\": ClassLabel(\n",
        "            num_classes=7,\n",
        "            names=[\"Sad\", \"Mad\", \"Scared\", \"Powerful\", \"Peaceful\", \"Joyful\", \"Neutral\"])\n",
        "    },\n",
        "    \"MPDD\": \n",
        "    {\n",
        "        \"Emotion\": ClassLabel(\n",
        "            num_classes=7,\n",
        "            names=[\"angry\", \"disgust\", \"fear\", \"joy\", \"neutral\", \"sadness\", \"surprise\"])\n",
        "    },\n",
        "}\n",
        "    \n",
        "tokenizer = AutoTokenizer.from_pretrained(kwargs[\"checkpoint\"])\n",
        "datasets = preprocess(tokenizer, dataset_labels, **kwargs)\n",
        "train_dataset, eval_dataset, test_dataset = prepare_datasets(datasets, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WPovLHVpxFIw"
      },
      "outputs": [],
      "source": [
        "tasks = {task: dataset_labels[task.split(\"_\")[0]][task.split(\"_\")[1]] for task in train_dataset.keys()}\n",
        "task_models = {\n",
        "        task: AutoModelForSequenceClassification.from_pretrained(\n",
        "            kwargs[\"checkpoint\"], \n",
        "            num_labels=label.num_classes,\n",
        "            max_length=1024)\n",
        "        for task, label in tasks.items()\n",
        "}\n",
        "multi_task_model = MultiTaskModel.from_task_models(task_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "brqjcRfFxFIw"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JpgsubuzxFIw"
      },
      "outputs": [],
      "source": [
        "if not kwargs[\"do_train\"]:\n",
        "    multi_task_model.load_state_dict(\n",
        "        torch.load(kwargs[\"model_file\"], map_location=torch.device(device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QLFPNeOYxFIw"
      },
      "outputs": [],
      "source": [
        "multi_task_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Zue7FyktxFIw"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    metric = load_metric(\"f1\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=kwargs[\"train_dir\"],\n",
        "    seed=kwargs[\"seed\"],\n",
        "    overwrite_output_dir=True,\n",
        "    label_names=[\"labels\"],\n",
        "    learning_rate=kwargs[\"learning_rate\"],\n",
        "    num_train_epochs=kwargs[\"epoch\"],\n",
        "    per_device_train_batch_size=kwargs[\"batch_size\"],\n",
        "    logging_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    remove_unused_columns=False,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_f1\"\n",
        ")\n",
        "\n",
        "trainer = MultiTaskTrainer(\n",
        "    multi_task_model,\n",
        "    training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "B-oOLuqLxFIx"
      },
      "outputs": [],
      "source": [
        "if kwargs[\"do_train\"]:\n",
        "    trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MetQKxvxxFIx"
      },
      "outputs": [],
      "source": [
        "pred = trainer.predict(test_dataset)\n",
        "f1 = pred.metrics['test_f1']\n",
        "print(\"Weighted F1:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "B9PORK38xFIx"
      },
      "outputs": [],
      "source": [
        "pred_labels = dataset_labels[kwargs[\"eval_dataset\"]][kwargs[\"eval_task\"]].int2str(pred.predictions.argmax(axis=-1))\n",
        "true_labels = dataset_labels[kwargs[\"eval_dataset\"]][kwargs[\"eval_task\"]].int2str(pred.label_ids)\n",
        "inputs = tokenizer.batch_decode(test_dataset[kwargs[\"eval_dataset\"] + \"_\" + kwargs[\"eval_task\"]][\"input_ids\"])\n",
        "f = open(kwargs[\"output_file\"], \"w\")\n",
        "f.write(\"Input\\tPredicted\\tTrue\\n\")\n",
        "f.write(\"\\n\".join([\"\\t\".join([input, pred_label, true_label]) \n",
        "                    for input, pred_label, true_label \n",
        "                    in zip(inputs, pred_labels, true_labels)]))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "O-o6Eo2rxFIx"
      },
      "outputs": [],
      "source": [
        "!mkdir -p results\n",
        "import json\n",
        "\n",
        "f = open(kwargs[\"result_file\"], \"a+\")\n",
        "f.write(json.dumps(kwargs))\n",
        "f.write(\"\\nWeighted F1: {}\\n\".format(f1))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "n_uKa1B6xFIx"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(kwargs[\"result_file\"])\n",
        "files.download(kwargs[\"output_file\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "i1WthgWKxFIx"
      },
      "outputs": [],
      "source": [
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tmpJmvq2xFIy"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/outputs/multi_task_model/pytorch_model.bin\" \"/content/gdrive/MyDrive/pytorch_model_en.bin\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DmpSNfMXW8AW",
        "Y7LZ98xqW3sk",
        "3vu9ks2HWodt"
      ],
      "name": "D2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
